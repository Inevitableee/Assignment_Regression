{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine \n",
    "import math\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.layouts import column, grid\n",
    "from bokeh.models import Band, ColumnDataSource\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Float, String\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasisOrganizer:\n",
    "    try:\n",
    "        def __init__(self, Location_Of_the_CSV):\n",
    "            \n",
    "            self._organizers = []\n",
    "\n",
    "            \n",
    "            try:\n",
    "                self._organizer_data = pd.read_csv(Location_Of_the_CSV)\n",
    "            except FileNotFoundError:\n",
    "                print(\"Error reading the CSV file {}\".format(Location_Of_the_CSV))\n",
    "                raise\n",
    "\n",
    "            \n",
    "            x_data = self._organizer_data[\"x\"]\n",
    "\n",
    "            \n",
    "            for lable_of_column, value_of_column in self._organizer_data.items():\n",
    "                if \"x\" in lable_of_column:\n",
    "                    continue\n",
    "                \n",
    "                subgroup = pd.concat([x_data, value_of_column], axis=1)\n",
    "                organizer = Organizer.from_dataframe(lable_of_column, subgroup)\n",
    "                self._organizers.append(organizer)\n",
    "\n",
    "\n",
    "        def to_sql(self, name_of_CSV, suffix):\n",
    "            \n",
    "            engine = create_engine('sqlite:///{}.db'.format(name_of_CSV), echo=False)\n",
    "\n",
    "            \n",
    "            Dupliacte_of_organizer_data = self._organizer_data.copy()\n",
    "            Dupliacte_of_organizer_data.columns = [title.capitalize() + suffix for title in Dupliacte_of_organizer_data.columns]\n",
    "            Dupliacte_of_organizer_data.set_index(Dupliacte_of_organizer_data.columns[0], inplace=True)\n",
    "\n",
    "            Dupliacte_of_organizer_data.to_sql(\n",
    "                name_of_CSV,\n",
    "                engine,\n",
    "                if_exists=\"replace\",\n",
    "                index=True,\n",
    "            )\n",
    "\n",
    "        @property\n",
    "        def organizers(self):\n",
    "            \n",
    "            return self._organizers\n",
    "\n",
    "        def __iter__(self):\n",
    "            \n",
    "            return BasisOrganizerRepeat(self)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return \"Contains {} number of organizers\".format(len(self.organizers))\n",
    "    except Exception as e:\n",
    "        print(\"Error in BasisOrganizer\"+ str(e))\n",
    "\n",
    "class BasisOrganizerRepeat():\n",
    "    try:\n",
    "        def __init__(self, organizer_administrator):\n",
    "            \n",
    "            self._index = 0\n",
    "            self._organizer_administrator = organizer_administrator\n",
    "\n",
    "        def __next__(self):\n",
    "            \n",
    "            if self._index < len(self._organizer_administrator.organizers):\n",
    "                value_requested = self._organizer_administrator.organizers[self._index]\n",
    "                self._index = self._index + 1\n",
    "                return value_requested\n",
    "            raise StopIteration\n",
    "    except Exception as e:\n",
    "        print(\"Error in BasisOrganizerRepeat\"+ str(e))\n",
    "\n",
    "\n",
    "class Organizer:\n",
    "    try:\n",
    "        def __init__(self, title):\n",
    "            \n",
    "            self._title = title\n",
    "            self.dataframe = pd.DataFrame()\n",
    "\n",
    "        def Finding_y_driven_from_x(self, x):\n",
    "            \n",
    "            search_key = self.dataframe[\"x\"] == x\n",
    "            try:\n",
    "                return self.dataframe.loc[search_key].iat[0, 1]\n",
    "            except IndexError:\n",
    "                raise IndexError\n",
    "\n",
    "\n",
    "        @property\n",
    "        def title(self):\n",
    "            \n",
    "            return self._title\n",
    "\n",
    "        def __iter__(self):\n",
    "            return OrganizerRepeat(self)\n",
    "\n",
    "        def __sub__(self, other):\n",
    "            \n",
    "            diff = self.dataframe - other.dataframe\n",
    "            return diff\n",
    "\n",
    "        @classmethod\n",
    "        def from_dataframe(cls, title, dataframe):\n",
    "            \n",
    "            organizer = cls(title)\n",
    "            organizer.dataframe = dataframe\n",
    "            organizer.dataframe.columns = [\"x\", \"y\"]\n",
    "            return organizer\n",
    "\n",
    "        def __repr__(self):\n",
    "            return \"Organizer for {}\".format(self.title)\n",
    "    except Exception as e:\n",
    "        print(\"Error in Organizer\"+ str(e))\n",
    "\n",
    "class IdealOrganizer(Organizer):\n",
    "    try:\n",
    "        def __init__(self, organizer, training_organizer, error):\n",
    "            \n",
    "            super().__init__(organizer.title)\n",
    "            self.dataframe = organizer.dataframe\n",
    "\n",
    "            self.training_organizer = training_organizer\n",
    "            self.error = error\n",
    "            self._forbearance_value = 1\n",
    "            self._forbearance = 1\n",
    "\n",
    "        def _decide_largest_variance(self, ideal_Organizer, train_Organizer):\n",
    "            \n",
    "            spans = train_Organizer - ideal_Organizer\n",
    "            spans[\"y\"] = spans[\"y\"].abs()\n",
    "            large_variance = max(spans[\"y\"])\n",
    "            return large_variance\n",
    "\n",
    "        @property\n",
    "        def forbearance(self):\n",
    "            \n",
    "            self._forbearance = self.forbearance_factor * self.large_variance\n",
    "            return self._forbearance\n",
    "\n",
    "        @forbearance.setter\n",
    "        def forbearance(self, value):\n",
    "\n",
    "            self._forbearance = value\n",
    "\n",
    "        @property\n",
    "        def forbearance_factor(self):\n",
    "            \n",
    "            return self._forbearance_value\n",
    "\n",
    "        @forbearance_factor.setter\n",
    "        def forbearance_factor(self, value):\n",
    "            self._forbearance_value = value\n",
    "\n",
    "        @property\n",
    "        def large_variance(self):\n",
    "            \n",
    "            large_variance = self._decide_largest_variance(self, self.training_organizer)\n",
    "            return large_variance\n",
    "    except Exception as e:\n",
    "        print(\"Error in IdealOrganizer\"+ str(e))\n",
    "\n",
    "\n",
    "class OrganizerRepeat:\n",
    "    try:\n",
    "        def __init__(self, organizer):\n",
    "            \n",
    "            self._organizer = organizer\n",
    "            self._index = 0\n",
    "\n",
    "        def __next__(self):\n",
    "            \n",
    "            if self._index < len(self._organizer.dataframe):\n",
    "                value_requested_series = (self._organizer.dataframe.iloc[self._index])\n",
    "                point = {\"x\": value_requested_series.x, \"y\": value_requested_series.y}\n",
    "                self._index += 1\n",
    "                return point\n",
    "            raise StopIteration\n",
    "    except Exception as e:\n",
    "        print(\"Error in OrganizerRepeat\"+ str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def P_Ideal_organizers(ideal_Organizers, name_of_CSV):\n",
    "    \n",
    "    ideal_Organizers.sort(key = lambda ideal_Organizer: ideal_Organizer.training_organizer.title, reverse=False)\n",
    "    plots = []\n",
    "    for ideal_Organizer in ideal_Organizers:\n",
    "        p = plot_Chart_from_two_Organizer(line_Organizer=ideal_Organizer, scatter_Organizer=ideal_Organizer.training_organizer,\n",
    "                                        quadratic_error=ideal_Organizer.error)\n",
    "        plots.append(p)\n",
    "    output_file(\"{}.html\".format(name_of_CSV))\n",
    "    \n",
    "    show(column(*plots))\n",
    "\n",
    "\n",
    "def plot_Bullets_with_their_ideal_Organizer(bullets_with_class, name_of_CSV):\n",
    "    \n",
    "    plots = []\n",
    "    for index, item in enumerate(bullets_with_class):\n",
    "        if item[\"classification\"] is not None:\n",
    "            p = plot_grading(item[\"point\"], item[\"classification\"])\n",
    "            plots.append(p)\n",
    "    output_file(\"{}.html\".format(name_of_CSV))\n",
    "    show(column(*plots))\n",
    "\n",
    "\n",
    "def plot_Chart_from_two_Organizer(scatter_Organizer, line_Organizer, quadratic_error):\n",
    "    \n",
    "    f1_dataframe = scatter_Organizer.dataframe\n",
    "    f1_name = scatter_Organizer.title\n",
    "\n",
    "    f2_dataframe = line_Organizer.dataframe\n",
    "    f2_name = line_Organizer.title\n",
    "\n",
    "    quadratic_error = round(quadratic_error, 2)\n",
    "    p = figure(title=\"train model {} vs ideal {}. Total squared error = {}\".format(f1_name, f2_name, quadratic_error),\n",
    "            x_axis_label='x', y_axis_label='y')\n",
    "    p.scatter(f1_dataframe[\"x\"], f1_dataframe[\"y\"], fill_color=\"red\", legend_label=\"Train\")\n",
    "    p.line(f2_dataframe[\"x\"], f2_dataframe[\"y\"], legend_label=\"Ideal\", line_width=2)\n",
    "    return p\n",
    "\n",
    "\n",
    "def plot_grading(point, ideal_Organizer):\n",
    "    \n",
    "    if ideal_Organizer is not None:\n",
    "        try:\n",
    "            classification_organizer_dataframe = ideal_Organizer.dataframe\n",
    "\n",
    "            point_str = \"({},{})\".format(point[\"x\"], round(point[\"y\"], 2))\n",
    "            title = \"point {} with classification: {}\".format(point_str, ideal_Organizer.title)\n",
    "\n",
    "            p = figure(title=title, x_axis_label='x', y_axis_label='y')\n",
    "\n",
    "            \n",
    "            p.line(classification_organizer_dataframe[\"x\"], classification_organizer_dataframe[\"y\"],\n",
    "                    legend_label=\"classification Organizer\", line_width=2, line_color='black')\n",
    "\n",
    "            \n",
    "            criterion = ideal_Organizer.forbearance\n",
    "            classification_organizer_dataframe['upper'] = classification_organizer_dataframe['y'] + criterion\n",
    "            classification_organizer_dataframe['lower'] = classification_organizer_dataframe['y'] - criterion\n",
    "\n",
    "            source = ColumnDataSource(classification_organizer_dataframe.reset_index())\n",
    "\n",
    "            band = Band(base='x', lower='lower', upper='upper', source=source, level='underlay',\n",
    "                fill_alpha=0.3, line_width=1, line_color='green', fill_color=\"green\")\n",
    "\n",
    "            p.add_layout(band)\n",
    "\n",
    "            \n",
    "            p.scatter([point[\"x\"]], [round(point[\"y\"], 4)], fill_color=\"red\", legend_label=\"Test point\", size=8)\n",
    "\n",
    "            return p\n",
    "        except Exception as e:\n",
    "            print(\"Error in plot_grading\"+ str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_loss(training_organizer, inventory_contender_organizers, losing_organizer):\n",
    "    try:    \n",
    "        function_with_smallest_error = None\n",
    "        smallest_error = None\n",
    "        for organizer in inventory_contender_organizers:\n",
    "            error = losing_organizer(training_organizer, organizer)\n",
    "            if ((smallest_error == None) or error < smallest_error):\n",
    "                smallest_error = error\n",
    "                function_with_smallest_error = organizer\n",
    "\n",
    "        ideal_Organizer = IdealOrganizer(organizer=function_with_smallest_error, training_organizer=training_organizer,\n",
    "                            error=smallest_error)\n",
    "        return ideal_Organizer\n",
    "    except Exception as e:\n",
    "            print(\"Error in reduce_loss\"+ str(e))\n",
    "\n",
    "\n",
    "def classification_search(point, ideal_Organizers):\n",
    "    \n",
    "    current_lowest_classification = None\n",
    "    current_lowest_span = None\n",
    "\n",
    "    for ideal_Organizer in ideal_Organizers:\n",
    "        try:\n",
    "            locate_y_in_classification = ideal_Organizer.Finding_y_driven_from_x(point[\"x\"])\n",
    "        except IndexError:\n",
    "            print(\"This point is not in the classification Organizer\")\n",
    "            raise IndexError\n",
    "\n",
    "        \n",
    "        span = abs(locate_y_in_classification - point[\"y\"])\n",
    "\n",
    "        if (abs(span < ideal_Organizer.forbearance)):\n",
    "            \n",
    "            if ((current_lowest_classification == None) or (span < current_lowest_span)):\n",
    "                current_lowest_classification = ideal_Organizer\n",
    "                current_lowest_span = span\n",
    "\n",
    "    return current_lowest_classification, current_lowest_span\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_variance_outcome_to_sqlite(result):\n",
    "    try:\n",
    "        engine = create_engine('sqlite:///{}.db'.format(\"Final_mapping\"), echo=False)\n",
    "        meadata = MetaData()\n",
    "        \n",
    "        Final_mapping =Table(\"Final_mapping\", meadata,\n",
    "                    Column('X (Test organizer)', Float, primary_key=False),\n",
    "                    Column('Y (Test organizer)', Float),\n",
    "                    Column('Delta Y (Test organizer)', Float),\n",
    "                    Column('No. of ideal organizer', String(50))\n",
    "        )\n",
    "        meadata.create_all(engine)\n",
    "\n",
    "        execute_map=[]\n",
    "        for item in result:\n",
    "            point = item[\"point\"]\n",
    "            classification  = item[\"classification\"]\n",
    "            delta_y = item[\"delta_y\"]\n",
    "            classification_name  = None\n",
    "            if classification  is not None:\n",
    "                classification_name = classification.title.replace(\"Y\",\"N\")\n",
    "            else:\n",
    "                classification_name = \"-\"\n",
    "                delta_y =-1\n",
    "            res = {\n",
    "                'X (Test organizer)': point[\"x\"],\n",
    "                'Y (Test organizer)': point[\"y\"],\n",
    "                'Delta Y (Test organizer)': delta_y,\n",
    "                'No. of ideal organizer': classification_name\n",
    "            }\n",
    "            execute_map.append(res)\n",
    "\n",
    "        with engine.begin() as connection:\n",
    "            connection.execute(Final_mapping.insert(), execute_map)\n",
    "    except Exception as e:\n",
    "            print(\"Error in write_variance_outcome_to_sqlite\"+ str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_error(first_function, second_function):\n",
    "    try:    \n",
    "        spans = second_function - first_function\n",
    "        spans[\"y\"] = spans[\"y\"] ** 2\n",
    "        entire_variance = sum(spans[\"y\"])\n",
    "        return entire_variance\n",
    "    except Exception as e:\n",
    "            print(\"Error in quadratic_error\"+ str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "GAIN_PART = math.sqrt(2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    ideal_directory = \"data/ideal.csv\"\n",
    "    train_directory = \"data/train.csv\"\n",
    "    test_directory = \"data/test.csv\"\n",
    "\n",
    "    \n",
    "    contender_ideal_Organizer_administrator = BasisOrganizer(Location_Of_the_CSV=ideal_directory)\n",
    "    train_Organizer_administrator = BasisOrganizer(Location_Of_the_CSV=train_directory)\n",
    "\n",
    "    \n",
    "    train_Organizer_administrator.to_sql(name_of_CSV=\"training\", suffix=\" (training func)\")\n",
    "    contender_ideal_Organizer_administrator.to_sql(name_of_CSV=\"ideal\", suffix=\" (ideal organizer)\")\n",
    "\n",
    "    \n",
    "    ideal_Organizers = []\n",
    "    for train_Organizer in train_Organizer_administrator:\n",
    "        \n",
    "        ideal_Organizer = reduce_loss(training_organizer=train_Organizer,\n",
    "                                    inventory_contender_organizers=contender_ideal_Organizer_administrator.organizers,\n",
    "                                    losing_organizer=quadratic_error)\n",
    "        ideal_Organizer.forbearance_factor = GAIN_PART\n",
    "        ideal_Organizers.append(ideal_Organizer)\n",
    "\n",
    "    \n",
    "    P_Ideal_organizers(ideal_Organizers, \"train_and_ideal\")\n",
    "\n",
    "    \n",
    "    \n",
    "    test_organizer_administrator = BasisOrganizer(Location_Of_the_CSV=test_directory)\n",
    "    test_organizer = test_organizer_administrator.organizers[0]\n",
    "\n",
    "    PW_ideal_Organizer = []\n",
    "    for point in test_organizer:\n",
    "        ideal_Organizer, delta_y = classification_search(point=point, ideal_Organizers=ideal_Organizers)\n",
    "        result = {\"point\": point, \"classification\": ideal_Organizer, \"delta_y\": delta_y}\n",
    "        PW_ideal_Organizer.append(result)\n",
    "\n",
    "    \n",
    "    plot_Bullets_with_their_ideal_Organizer(PW_ideal_Organizer, \"point_and_ideal\")\n",
    "\n",
    "    \n",
    "    write_variance_outcome_to_sqlite(PW_ideal_Organizer)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
